{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "from six.moves import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트 불러오기 : 'linux_kernel/input.txt'\n"
     ]
    }
   ],
   "source": [
    "# Load text\n",
    "data_dir    = \"linux_kernel\"\n",
    "save_dir    = \"linux_kernel\"\n",
    "input_file  = os.path.join(data_dir, \"input.txt\")\n",
    "with open(input_file, \"r\") as f:\n",
    "    data = f.read()\n",
    "print (\"텍스트 불러오기 : '%s'\" % (input_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'counter.items()' is <class 'dict_items'> and length is 98\n",
      "[0/3]\n",
      "('y', 10830)\n",
      "[1/3]\n",
      "('q', 4908)\n",
      "[2/3]\n",
      "('j', 946)\n",
      "[3/3]\n",
      "('g', 19111)\n",
      "[4/3]\n",
      "('s', 75011)\n",
      " \n",
      "Type of 'count_pairs' is <class 'list'> and length is 98\n",
      "[0/3]\n",
      "(' ', 171222)\n",
      "[1/3]\n",
      "('e', 113021)\n",
      "[2/3]\n",
      "('t', 102154)\n",
      "[3/3]\n",
      "('r', 76185)\n",
      "[4/3]\n",
      "('i', 75486)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess Text\n",
    "# First, count the number of characters\n",
    "counter = collections.Counter(data)\n",
    "count_pairs = sorted(counter.items(), key=lambda x: -x[1]) # <= Sort\n",
    "print (\"Type of 'counter.items()' is %s and length is %d\" \n",
    "       % (type(counter.items()), len(counter.items()))) \n",
    "for i in range(5):\n",
    "    print (\"[%d/%d]\" % (i, 3)), # <= This comma remove '\\n'\n",
    "    print (list(counter.items())[i])\n",
    "\n",
    "print (\" \")\n",
    "print (\"Type of 'count_pairs' is %s and length is %d\" \n",
    "       % (type(count_pairs), len(count_pairs))) \n",
    "for i in range(5):\n",
    "    print (\"[%d/%d]\" % (i, 3)), # <= This comma remove '\\n'\n",
    "    print (count_pairs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'chars' is <class 'tuple'> and length is 98\n",
      "[0/3]\n",
      "chars[0] is ' '\n",
      "[1/3]\n",
      "chars[1] is 'e'\n",
      "[2/3]\n",
      "chars[2] is 't'\n",
      "[3/3]\n",
      "chars[3] is 'r'\n",
      "[4/3]\n",
      "chars[4] is 'i'\n",
      "\n",
      "Type of 'vocab' is <class 'dict'> and length is 98\n",
      "[0/3]\n",
      "vocab[' '] is 0\n",
      "[1/3]\n",
      "vocab['e'] is 1\n",
      "[2/3]\n",
      "vocab['t'] is 2\n",
      "[3/3]\n",
      "vocab['r'] is 3\n",
      "[4/3]\n",
      "vocab['i'] is 4\n"
     ]
    }
   ],
   "source": [
    "# Let's make dictionary\n",
    "chars, counts = zip(*count_pairs)\n",
    "vocab = dict(zip(chars, range(len(chars))))\n",
    "print (\"Type of 'chars' is %s and length is %d\" \n",
    "    % (type(chars), len(chars))) \n",
    "for i in range(5):\n",
    "    print (\"[%d/%d]\" % (i, 3)), # <= This comma remove '\\n'\n",
    "    print (\"chars[%d] is '%s'\" % (i, chars[i]))\n",
    "    \n",
    "print (\"\")\n",
    "\n",
    "print (\"Type of 'vocab' is %s and length is %d\" \n",
    "    % (type(vocab), len(vocab))) \n",
    "for i in range(5):\n",
    "    print (\"[%d/%d]\" % (i, 3)), # <= This comma remove '\\n'\n",
    "    print (\"vocab['%s'] is %s\" % (chars[i], vocab[chars[i]]))\n",
    "    \n",
    "# SAve chars and vocab\n",
    "with open(os.path.join(save_dir, 'chars_vocab.pkl'), 'wb') as f:\n",
    "    cPickle.dump((chars, vocab), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chars[0] converts index to char\n",
    "# vocab['a'] converts char to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'corpus' is <class 'numpy.ndarray'>, shape is (1708870,), and length is 1708870\n",
      "\n",
      "'corpus' looks like [36 22  7  0 22  0  0 13  4  8]\n",
      "[0/10] chars[36] corresponds to '/'\n",
      "[1/10] chars[22] corresponds to '*'\n",
      "[2/10] chars[07] corresponds to '\n",
      "'\n",
      "[3/10] chars[00] corresponds to ' '\n",
      "[4/10] chars[22] corresponds to '*'\n",
      "[5/10] chars[00] corresponds to ' '\n",
      "[6/10] chars[00] corresponds to ' '\n",
      "[7/10] chars[13] corresponds to 'l'\n",
      "[8/10] chars[04] corresponds to 'i'\n",
      "[9/10] chars[08] corresponds to 'n'\n"
     ]
    }
   ],
   "source": [
    "# Now convert all text to index using vocab! \n",
    "corpus = np.array(list(map(vocab.get, data)))\n",
    "print (\"Type of 'corpus' is %s, shape is %s, and length is %d\" \n",
    "    % (type(corpus), corpus.shape, len(corpus)))\n",
    "\n",
    "check_len = 10\n",
    "print (\"\\n'corpus' looks like %s\" % (corpus[0:check_len]))\n",
    "for i in range(check_len):\n",
    "    _wordidx = corpus[i]\n",
    "    print (\"[%d/%d] chars[%02d] corresponds to '%s'\" \n",
    "           % (i, check_len, _wordidx, chars[_wordidx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xdata is ... [36 22  7 ..., 25  3  9] and length is 1700000\n",
      "ydata is ... [22  7  0 ...,  3  9 36] and length is 1700000\n",
      "\n",
      "Type of 'xbatches' is <class 'list'> and length is 170\n",
      "Type of 'ybatches' is <class 'list'> and length is 170\n",
      "\n",
      "Type of 'temp' is <class 'list'> and length is 5\n",
      "Type of 'temp[0]' is <class 'numpy.ndarray'> and shape is (50, 200)\n",
      "Type of 'temp[1]' is <class 'numpy.ndarray'> and shape is (50, 200)\n",
      "Type of 'temp[2]' is <class 'numpy.ndarray'> and shape is (50, 200)\n",
      "Type of 'temp[3]' is <class 'numpy.ndarray'> and shape is (50, 200)\n",
      "Type of 'temp[4]' is <class 'numpy.ndarray'> and shape is (50, 200)\n"
     ]
    }
   ],
   "source": [
    "# Generate batch data \n",
    "batch_size  = 50\n",
    "seq_length  = 200\n",
    "num_batches = int(corpus.size / (batch_size * seq_length))\n",
    "# First, reduce the length of corpus to fit batch_size\n",
    "corpus_reduced = corpus[:(num_batches*batch_size*seq_length)]\n",
    "xdata = corpus_reduced\n",
    "ydata = np.copy(xdata)\n",
    "ydata[:-1] = xdata[1:]\n",
    "ydata[-1]  = xdata[0]\n",
    "print ('xdata is ... %s and length is %d' % (xdata, xdata.size))\n",
    "print ('ydata is ... %s and length is %d' % (ydata, xdata.size))\n",
    "print (\"\")\n",
    "\n",
    "# Second, make batch \n",
    "xbatches = np.split(xdata.reshape(batch_size, -1), num_batches, 1)\n",
    "ybatches = np.split(ydata.reshape(batch_size, -1), num_batches, 1)\n",
    "print (\"Type of 'xbatches' is %s and length is %d\" \n",
    "    % (type(xbatches), len(xbatches)))\n",
    "print (\"Type of 'ybatches' is %s and length is %d\" \n",
    "    % (type(ybatches), len(ybatches)))\n",
    "print (\"\")\n",
    "\n",
    "# How can we access to xbatches?? \n",
    "nbatch = 5\n",
    "temp = xbatches[0:nbatch]\n",
    "print (\"Type of 'temp' is %s and length is %d\" \n",
    "    % (type(temp), len(temp)))\n",
    "for i in range(nbatch):\n",
    "    temp2 = temp[i]\n",
    "    print (\"Type of 'temp[%d]' is %s and shape is %s\" % (i, type(temp2), temp2.shape,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we are ready to make our RNN model with seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그래프 준비됨\n"
     ]
    }
   ],
   "source": [
    "# Important RNN parameters \n",
    "vocab_size = len(vocab)\n",
    "rnn_size   = 128\n",
    "num_layers = 2\n",
    "grad_clip  = 5.\n",
    "\n",
    "# Construct RNN model \n",
    "unitcell   = tf.nn.rnn_cell.BasicLSTMCell(rnn_size)\n",
    "cell       = tf.nn.rnn_cell.MultiRNNCell([unitcell] * num_layers)\n",
    "input_data = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "targets    = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "istate     = cell.zero_state(batch_size, tf.float32)\n",
    "# Weigths \n",
    "with tf.variable_scope('rnnlm'):\n",
    "    softmax_w = tf.get_variable(\"softmax_w\", [rnn_size, vocab_size])\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "\n",
    "    embedding = tf.get_variable(\"embedding\", [vocab_size, rnn_size])\n",
    "    inputs = tf.split(1, seq_length, tf.nn.embedding_lookup(embedding, input_data))\n",
    "    inputs = [tf.squeeze(_input, [1]) for _input in inputs]\n",
    "# Output\n",
    "def loop(prev, _):\n",
    "    prev = tf.nn.xw_plus_b(prev, softmax_w, softmax_b)\n",
    "    prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n",
    "    return tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    "\"\"\"\n",
    "    loop_function: If not None, this function will be applied to the i-th output\n",
    "    in order to generate the i+1-st input, and decoder_inputs will be ignored,\n",
    "    except for the first element (\"GO\" symbol).\n",
    "\"\"\" \n",
    "outputs, last_state = tf.nn.seq2seq.rnn_decoder(inputs, istate, cell\n",
    "                , loop_function=None, scope='rnnlm')\n",
    "output = tf.reshape(tf.concat(1, outputs), [-1, rnn_size])\n",
    "logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)\n",
    "probs  = tf.nn.softmax(logits)\n",
    "# Loss\n",
    "loss = tf.nn.seq2seq.sequence_loss_by_example([logits], # Input\n",
    "    [tf.reshape(targets, [-1])], # Target\n",
    "    [tf.ones([batch_size * seq_length])], # Weight \n",
    "    vocab_size)\n",
    "# Optimizer\n",
    "cost     = tf.reduce_sum(loss) / batch_size / seq_length\n",
    "final_state = last_state\n",
    "lr       = tf.Variable(0.0, trainable=False)\n",
    "tvars    = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), grad_clip)\n",
    "_optm    = tf.train.AdamOptimizer(lr)\n",
    "optm     = _optm.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "print (\"그래프 준비됨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-4e02eff36cc7>:15 in <module>.: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2016-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "[0/8500] cost: 5.0432 / Each batch learning took 2.4016 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[100/8500] cost: 2.9739 / Each batch learning took 0.0897 sec\n",
      "[200/8500] cost: 2.4961 / Each batch learning took 0.0899 sec\n",
      "[300/8500] cost: 2.3594 / Each batch learning took 0.0897 sec\n",
      "[400/8500] cost: 2.1653 / Each batch learning took 0.1573 sec\n",
      "[500/8500] cost: 1.9400 / Each batch learning took 0.1078 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[600/8500] cost: 1.8971 / Each batch learning took 0.0898 sec\n",
      "[700/8500] cost: 1.7494 / Each batch learning took 0.0935 sec\n",
      "[800/8500] cost: 1.7391 / Each batch learning took 0.0901 sec\n",
      "[900/8500] cost: 1.6910 / Each batch learning took 0.1138 sec\n",
      "[1000/8500] cost: 1.5949 / Each batch learning took 0.1059 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[1100/8500] cost: 1.5950 / Each batch learning took 0.0899 sec\n",
      "[1200/8500] cost: 1.4401 / Each batch learning took 0.1037 sec\n",
      "[1300/8500] cost: 1.5712 / Each batch learning took 0.0892 sec\n",
      "[1400/8500] cost: 1.4906 / Each batch learning took 0.0905 sec\n",
      "[1500/8500] cost: 1.5050 / Each batch learning took 0.1577 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[1600/8500] cost: 1.5068 / Each batch learning took 0.1067 sec\n",
      "[1700/8500] cost: 1.4821 / Each batch learning took 0.1083 sec\n",
      "[1800/8500] cost: 1.4075 / Each batch learning took 0.0912 sec\n",
      "[1900/8500] cost: 1.3743 / Each batch learning took 0.1030 sec\n",
      "[2000/8500] cost: 1.4359 / Each batch learning took 0.0898 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[2100/8500] cost: 1.4270 / Each batch learning took 0.1061 sec\n",
      "[2200/8500] cost: 1.3415 / Each batch learning took 0.0887 sec\n",
      "[2300/8500] cost: 1.3510 / Each batch learning took 0.0892 sec\n",
      "[2400/8500] cost: 1.2910 / Each batch learning took 0.0901 sec\n",
      "[2500/8500] cost: 1.3091 / Each batch learning took 0.0890 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[2600/8500] cost: 1.3004 / Each batch learning took 0.0896 sec\n",
      "[2700/8500] cost: 1.2695 / Each batch learning took 0.1061 sec\n",
      "[2800/8500] cost: 1.3157 / Each batch learning took 0.1137 sec\n",
      "[2900/8500] cost: 1.1759 / Each batch learning took 0.0904 sec\n",
      "[3000/8500] cost: 1.3175 / Each batch learning took 0.1026 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[3100/8500] cost: 1.2677 / Each batch learning took 0.1055 sec\n",
      "[3200/8500] cost: 1.2938 / Each batch learning took 0.1060 sec\n",
      "[3300/8500] cost: 1.3013 / Each batch learning took 0.0893 sec\n",
      "[3400/8500] cost: 1.2970 / Each batch learning took 0.1559 sec\n",
      "[3500/8500] cost: 1.2474 / Each batch learning took 0.0886 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[3600/8500] cost: 1.2271 / Each batch learning took 0.1056 sec\n",
      "[3700/8500] cost: 1.2760 / Each batch learning took 0.0896 sec\n",
      "[3800/8500] cost: 1.2764 / Each batch learning took 0.1063 sec\n",
      "[3900/8500] cost: 1.2193 / Each batch learning took 0.0894 sec\n",
      "[4000/8500] cost: 1.2103 / Each batch learning took 0.0896 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[4100/8500] cost: 1.1680 / Each batch learning took 0.0889 sec\n",
      "[4200/8500] cost: 1.1896 / Each batch learning took 0.1058 sec\n",
      "[4300/8500] cost: 1.1795 / Each batch learning took 0.1059 sec\n",
      "[4400/8500] cost: 1.1672 / Each batch learning took 0.0903 sec\n",
      "[4500/8500] cost: 1.2217 / Each batch learning took 0.1600 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[4600/8500] cost: 1.0816 / Each batch learning took 0.0886 sec\n",
      "[4700/8500] cost: 1.2166 / Each batch learning took 0.1590 sec\n",
      "[4800/8500] cost: 1.1791 / Each batch learning took 0.1061 sec\n",
      "[4900/8500] cost: 1.2045 / Each batch learning took 0.1060 sec\n",
      "[5000/8500] cost: 1.2111 / Each batch learning took 0.0904 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[5100/8500] cost: 1.2074 / Each batch learning took 0.1593 sec\n",
      "[5200/8500] cost: 1.1772 / Each batch learning took 0.0908 sec\n",
      "[5300/8500] cost: 1.1658 / Each batch learning took 0.0901 sec\n",
      "[5400/8500] cost: 1.1934 / Each batch learning took 0.1113 sec\n",
      "[5500/8500] cost: 1.2041 / Each batch learning took 0.1063 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[5600/8500] cost: 1.1625 / Each batch learning took 0.0924 sec\n",
      "[5700/8500] cost: 1.1439 / Each batch learning took 0.0895 sec\n",
      "[5800/8500] cost: 1.1082 / Each batch learning took 0.1098 sec\n",
      "[5900/8500] cost: 1.1277 / Each batch learning took 0.0893 sec\n",
      "[6000/8500] cost: 1.1212 / Each batch learning took 0.0887 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[6100/8500] cost: 1.1117 / Each batch learning took 0.0896 sec\n",
      "[6200/8500] cost: 1.1693 / Each batch learning took 0.0903 sec\n",
      "[6300/8500] cost: 1.0302 / Each batch learning took 0.1102 sec\n",
      "[6400/8500] cost: 1.1621 / Each batch learning took 0.0889 sec\n",
      "[6500/8500] cost: 1.1298 / Each batch learning took 0.1083 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[6600/8500] cost: 1.1582 / Each batch learning took 0.0903 sec\n",
      "[6700/8500] cost: 1.1600 / Each batch learning took 0.0900 sec\n",
      "[6800/8500] cost: 1.1547 / Each batch learning took 0.1072 sec\n",
      "[6900/8500] cost: 1.1351 / Each batch learning took 0.0897 sec\n",
      "[7000/8500] cost: 1.1316 / Each batch learning took 0.0900 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[7100/8500] cost: 1.1477 / Each batch learning took 0.1066 sec\n",
      "[7200/8500] cost: 1.1585 / Each batch learning took 0.0914 sec\n",
      "[7300/8500] cost: 1.1290 / Each batch learning took 0.0903 sec\n",
      "[7400/8500] cost: 1.1031 / Each batch learning took 0.0897 sec\n",
      "[7500/8500] cost: 1.0731 / Each batch learning took 0.1491 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[7600/8500] cost: 1.0905 / Each batch learning took 0.1490 sec\n",
      "[7700/8500] cost: 1.0864 / Each batch learning took 0.0924 sec\n",
      "[7800/8500] cost: 1.0784 / Each batch learning took 0.1069 sec\n",
      "[7900/8500] cost: 1.1342 / Each batch learning took 0.0894 sec\n",
      "[8000/8500] cost: 0.9985 / Each batch learning took 0.1058 sec\n",
      "모델 저장됨 : 'linux_kernel/model.ckpt'\n",
      "[8100/8500] cost: 1.1272 / Each batch learning took 0.1131 sec\n",
      "[8200/8500] cost: 1.0989 / Each batch learning took 0.1138 sec\n",
      "[8300/8500] cost: 1.1274 / Each batch learning took 0.1084 sec\n",
      "[8400/8500] cost: 1.1265 / Each batch learning took 0.1562 sec\n"
     ]
    }
   ],
   "source": [
    "# Train the model!\n",
    "num_epochs    = 50\n",
    "save_every    = 500\n",
    "learning_rate = 0.002\n",
    "decay_rate    = 0.97\n",
    "\n",
    "# 세션 설정\n",
    "session_conf = tf.ConfigProto()\n",
    "session_conf.gpu_options.allow_growth = True\n",
    "\n",
    "# 그래프 실행\n",
    "sess = tf.Session(config=session_conf)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "summary_writer = tf.train.SummaryWriter(save_dir, graph=sess.graph)\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "init_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    # Learning rate scheduling \n",
    "    sess.run(tf.assign(lr, learning_rate * (decay_rate ** epoch)))\n",
    "    state     = sess.run(istate)\n",
    "    batchidx  = 0\n",
    "    for iteration in range(num_batches):\n",
    "        start_time   = time.time()\n",
    "        randbatchidx = np.random.randint(num_batches)\n",
    "        xbatch       = xbatches[batchidx]\n",
    "        ybatch       = ybatches[batchidx]\n",
    "        batchidx     = batchidx + 1\n",
    "        \n",
    "        # Note that, num_batches = len(xbatches)\n",
    "        # 훈련! \n",
    "        train_loss, state, _ = sess.run([cost, final_state, optm]\n",
    "            , feed_dict={input_data: xbatch, targets: ybatch, istate: state}) \n",
    "        total_iter = epoch*num_batches + iteration\n",
    "        end_time     = time.time();\n",
    "        duration     = end_time - start_time\n",
    "        \n",
    "        if total_iter % 100 == 0:\n",
    "            print (\"[%d/%d] cost: %.4f / Each batch learning took %.4f sec\" \n",
    "                   % (total_iter, num_epochs*num_batches, train_loss, duration))\n",
    "        if total_iter % save_every == 0: \n",
    "            ckpt_path = os.path.join(save_dir, 'model.ckpt')\n",
    "            saver.save(sess, ckpt_path, global_step = total_iter)\n",
    "            # Save network! \n",
    "            print(\"모델 저장됨 : '%s'\" % (ckpt_path)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 콘솔에서 실행\n",
    "##### tensorboard --logdir=linux_kernel\n",
    "### http://localhost:6006/ 브라우저에서 열기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료!! 1160.6289 초 걸림. \n"
     ]
    }
   ],
   "source": [
    "print (\"완료!! %.4f 초 걸림. \" %(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
