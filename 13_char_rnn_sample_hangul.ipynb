{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Hangul RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Import Packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import string\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "from TextLoader import *\n",
    "from Hangulpy3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset using TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading preprocessed files\n",
      "type of 'data_loader' is <class 'dict'>, length is 76\n",
      "\n",
      "\n",
      "data_loader.vocab looks like \n",
      "{'ㄿ': 56, 'ㅋ': 42, 'ㅘ': 26, 'ㅌ': 30, 'ㅙ': 53, '.': 24, 'ㅍ': 31, 'ㅣ': 6, 'ㅚ': 33, 'ㅁ': 12, '!': 52, 'ㅢ': 25, 'ㄱ': 7, 'ㅆ': 22, 'ㅒ': 74, '?': 41, 'ㅃ': 47, 'ᴥ': 0, '(': 45, 'ㅇ': 2, 'ㄳ': 60, 'ㅉ': 40, 'ㅖ': 39, 'ㅔ': 20, 'ㅅ': 10, 'ㅝ': 36, 'ㅂ': 17, 'ㅛ': 38, 'ㄺ': 48, 'ㅟ': 35, 'ㄷ': 13, 'ㅡ': 8, ' ': 1, '7': 71, 'ㄲ': 29, '2': 62, '\"': 28, 'ㄼ': 54, 'ㅓ': 11, 'ㅀ': 51, 'ㄾ': 70, 'ㅗ': 9, 'ㄴ': 4, '\\x1a': 72, ')': 46, 'ㅐ': 21, 'ㅎ': 14, 'ㄹ': 5, 'ㅊ': 23, 'ㄻ': 55, 'ㅈ': 15, '1': 58, 'ㅜ': 16, '_': 69, '0': 73, '3': 66, \"'\": 49, '6': 59, '4': 67, 'ㄵ': 50, '5': 63, 'ㅞ': 61, '-': 65, 'ㅕ': 18, '\\n': 19, 'ㅄ': 43, 'ㅑ': 34, '9': 64, 'ㅠ': 37, 'ㄸ': 32, 'ㄶ': 44, ':': 57, '>': 75, 'ㅏ': 3, ',': 27, '8': 68} \n",
      "\n",
      "\n",
      "type of 'data_loader.chars' is <class 'tuple'>, length is 76\n",
      "\n",
      "\n",
      "data_loader.chars looks like \n",
      "('ᴥ', ' ', 'ㅇ', 'ㅏ', 'ㄴ', 'ㄹ', 'ㅣ', 'ㄱ', 'ㅡ', 'ㅗ', 'ㅅ', 'ㅓ', 'ㅁ', 'ㄷ', 'ㅎ', 'ㅈ', 'ㅜ', 'ㅂ', 'ㅕ', '\\n', 'ㅔ', 'ㅐ', 'ㅆ', 'ㅊ', '.', 'ㅢ', 'ㅘ', ',', '\"', 'ㄲ', 'ㅌ', 'ㅍ', 'ㄸ', 'ㅚ', 'ㅑ', 'ㅟ', 'ㅝ', 'ㅠ', 'ㅛ', 'ㅖ', 'ㅉ', '?', 'ㅋ', 'ㅄ', 'ㄶ', '(', ')', 'ㅃ', 'ㄺ', \"'\", 'ㄵ', 'ㅀ', '!', 'ㅙ', 'ㄼ', 'ㄻ', 'ㄿ', ':', '1', '6', 'ㄳ', 'ㅞ', '2', '5', '9', '-', '3', '4', '8', '_', 'ㄾ', '7', '\\x1a', '0', 'ㅒ', '>') \n"
     ]
    }
   ],
   "source": [
    "data_dir    = \"nine_dreams\"\n",
    "batch_size  = 50\n",
    "seq_length  = 50\n",
    "data_loader = TextLoader(data_dir, batch_size, seq_length)\n",
    "# This makes \"vocab.pkl\" and \"data.npy\" in \"nine_dreams\"   \n",
    "#  from \"nine_dreams/input.txt\" \n",
    "vocab_size = data_loader.vocab_size\n",
    "vocab = data_loader.vocab\n",
    "chars = data_loader.chars\n",
    "print ( \"type of 'data_loader' is %s, length is %d\" \n",
    "       % (type(data_loader.vocab), len(data_loader.vocab)) )\n",
    "print ( \"\\n\" )\n",
    "print (\"data_loader.vocab looks like \\n%s \" %\n",
    "       (data_loader.vocab))\n",
    "print ( \"\\n\" )\n",
    "print ( \"type of 'data_loader.chars' is %s, length is %d\" \n",
    "       % (type(data_loader.chars), len(data_loader.chars)) )\n",
    "print ( \"\\n\" )\n",
    "print (\"data_loader.chars looks like \\n%s \" % (data_loader.chars,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그래프 준비됨\n"
     ]
    }
   ],
   "source": [
    "rnn_size   = 512\n",
    "num_layers = 3\n",
    "grad_clip  = 5.\n",
    "\n",
    "_batch_size = 1\n",
    "_seq_length = 1\n",
    "\n",
    "vocab_size = data_loader.vocab_size\n",
    "\n",
    "\n",
    "# Select RNN Cell\n",
    "unitcell = tf.nn.rnn_cell.BasicLSTMCell(rnn_size)\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell([unitcell] * num_layers)\n",
    "# Set paths to the graph \n",
    "input_data = tf.placeholder(tf.int32, [_batch_size, _seq_length])\n",
    "targets    = tf.placeholder(tf.int32, [_batch_size, _seq_length])\n",
    "initial_state = cell.zero_state(_batch_size, tf.float32)\n",
    "\n",
    "# Set Network\n",
    "with tf.variable_scope('rnnlm'):\n",
    "    softmax_w = tf.get_variable(\"softmax_w\", [rnn_size, vocab_size])\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        embedding = tf.get_variable(\"embedding\", [vocab_size, rnn_size])\n",
    "        inputs = tf.split(1, _seq_length, tf.nn.embedding_lookup(embedding, input_data))\n",
    "        inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n",
    "\n",
    "# Loop function for seq2seq\n",
    "def loop(prev, _):\n",
    "    prev = tf.nn.xw_plus_b(prev, softmax_w, softmax_b)\n",
    "    prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n",
    "    return tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    "# Output of RNN \n",
    "outputs, last_state = tf.nn.seq2seq.rnn_decoder(inputs, initial_state\n",
    "                            , cell, loop_function=None, scope='rnnlm')\n",
    "output = tf.reshape(tf.concat(1, outputs), [-1, rnn_size])\n",
    "logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)\n",
    "# Next word probability \n",
    "probs = tf.nn.softmax(logits)\n",
    "# Define LOSS\n",
    "loss = tf.nn.seq2seq.sequence_loss_by_example([logits], # Input\n",
    "    [tf.reshape(targets, [-1])], # Target\n",
    "    [tf.ones([_batch_size * _seq_length])], # Weight \n",
    "    vocab_size)\n",
    "# Define Optimizer\n",
    "cost = tf.reduce_sum(loss) / _batch_size / _seq_length\n",
    "final_state = last_state\n",
    "lr = tf.Variable(0.0, trainable=False)\n",
    "tvars = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), grad_clip)\n",
    "_optm = tf.train.AdamOptimizer(lr)\n",
    "optm = _optm.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "print (\"그래프 준비됨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플링 함수 완료.\n"
     ]
    }
   ],
   "source": [
    "# Sample ! \n",
    "def sample( sess, chars, vocab, __probs, num=200, prime=u'ㅇㅗᴥㄴㅡㄹᴥ '):\n",
    "    state = sess.run(cell.zero_state(1, tf.float32))\n",
    "    _probs = __probs\n",
    "    prime = list(prime)\n",
    "    for char in prime[:-1]:\n",
    "        x = np.zeros((1, 1))\n",
    "        x[0, 0] = vocab[char]\n",
    "        feed = {input_data: x, initial_state:state}\n",
    "        [state] = sess.run([final_state], feed)\n",
    "\n",
    "    def weighted_pick(weights):\n",
    "        weights = weights / np.sum(weights) \n",
    "        t = np.cumsum(weights)\n",
    "        s = np.sum(weights)\n",
    "        return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "\n",
    "    ret = prime\n",
    "    char = prime[-1]\n",
    "    for n in range(num):\n",
    "        x = np.zeros((1, 1))\n",
    "        x[0, 0] = vocab[char]\n",
    "        feed = {input_data: x, initial_state:state}\n",
    "        [_probsval, state] = sess.run([_probs, final_state], feed)\n",
    "        p = _probsval[0]\n",
    "        sample = int(np.random.choice(len(p), p=p))\n",
    "        # sample = weighted_pick(p)\n",
    "        # sample = np.argmax(p)\n",
    "        pred = chars[sample]\n",
    "        ret += pred\n",
    "        char = pred\n",
    "    return ret\n",
    "print (\"샘플링 함수 완료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prime Text : 누구  => ㄴㅜᴥㄱㅜᴥ \n",
      "nine_dreams/model.ckpt-4000\n",
      "예시 문장 = ['ㄴ', 'ㅜ', 'ᴥ', 'ㄱ', 'ㅜ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅂ', 'ㅏ', 'ㄲ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㅇ', 'ㅟ', 'ᴥ', 'ㅇ', 'ㅔ', 'ᴥ', ' ', 'ㄷ', 'ㅏ', 'ᴥ', 'ㅅ', 'ㅣ', 'ᴥ', ' ', 'ㅈ', 'ㅜ', 'ᴥ', 'ㅁ', 'ㅗ', 'ㄴ', 'ᴥ', ' ', 'ㄷ', 'ㅡ', 'ㄹ', 'ᴥ', 'ㅇ', 'ㅗ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㅁ', 'ㅏ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㅊ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㄱ', 'ㅜ', 'ᴥ', 'ㅎ', 'ㅏ', 'ㅁ', 'ᴥ', 'ㄷ', 'ㅣ', 'ㄴ', 'ᴥ', ' ', 'ㅁ', 'ㅏ', 'ᴥ', 'ㅇ', 'ㅕ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㅇ', 'ㅓ', 'ᴥ', 'ㅅ', 'ㅣ', 'ᴥ', 'ㄱ', 'ㅣ', 'ᴥ', ' ', 'ㄱ', 'ㅏ', 'ㅌ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ㅍ', 'ᴥ', 'ㄸ', 'ㅣ', 'ᴥ', ' ', '\\n', 'ㄱ', 'ㅏ', 'ㅌ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㄸ', 'ㅗ', 'ᴥ', 'ㅎ', 'ㅏ', 'ㄴ', 'ᴥ', 'ㄴ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㄱ', 'ㅡ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ㄹ', 'ᴥ', 'ㅇ', 'ㅡ', 'ᴥ', 'ㄹ', 'ㅣ', 'ᴥ', 'ㄹ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㅃ', 'ㅓ', 'ㄴ', 'ᴥ', 'ㅈ', 'ㅏ', 'ㄱ', 'ᴥ', 'ㄱ', 'ㅏ', 'ㅁ', 'ᴥ', ' ', 'ㄱ', 'ㅠ', 'ㅇ', 'ᴥ', 'ㄱ', 'ㅕ', 'ㅇ', 'ᴥ', 'ㅅ', 'ㅣ', 'ᴥ', 'ㄹ', 'ㅕ', 'ᴥ', 'ㅂ', 'ㅏ', 'ㅂ', 'ᴥ', 'ㅇ', 'ㅡ', 'ᴥ', 'ㄹ', 'ㅗ', 'ᴥ', ' ', 'ㅂ', 'ㅓ', 'ᴥ', 'ㅁ', 'ㅕ', 'ᴥ', ' ', '\\n', 'ㅂ', 'ㅕ', 'ᴥ', 'ㄹ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㄹ', 'ㅡ', 'ㅁ', 'ᴥ', 'ㅎ', 'ㅏ', 'ᴥ', 'ㅇ', 'ㅕ', 'ᴥ', ' ', 'ㅈ', 'ㅓ', 'ㄱ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㄱ', 'ㅗ', 'ㅇ', 'ᴥ', 'ㅈ', 'ㅐ', 'ᴥ', 'ㅇ', 'ㅔ', 'ᴥ', ' ', 'ㄴ', 'ㅐ', 'ㄴ', 'ᴥ', 'ㄹ', 'ㅣ', 'ᴥ', 'ㄹ', 'ㅏ', 'ᴥ', ' ', 'ㅎ', 'ㅏ', 'ㄹ', 'ᴥ', 'ㅈ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㄷ', 'ㅏ', 'ᴥ', ',', ' ', 'ㅁ', 'ㅗ', 'ㅅ', 'ᴥ', 'ㅇ', 'ㅡ', 'ᴥ', 'ㄹ', 'ㅗ', 'ᴥ', ' ', 'ㄷ', 'ㅏ', 'ᴥ', 'ㄷ', 'ㅓ', 'ᴥ', 'ㄴ', 'ㅣ', 'ᴥ', 'ㅇ', 'ㅘ', 'ᴥ', ' ', 'ㅈ', 'ㅗ', 'ᴥ', 'ㄴ', 'ㅑ', 'ㅇ', 'ᴥ', 'ㅇ', 'ㅢ', 'ᴥ', 'ㄹ', 'ㅣ', 'ᴥ', 'ㄷ', 'ㅗ', 'ᴥ', ' ', 'ㅊ', 'ㅓ', 'ㅁ', 'ᴥ', 'ㅇ', 'ㅜ', 'ᴥ', 'ㄹ', 'ㅗ', 'ᴥ', ' ', 'ㅂ', 'ㅜ', 'ᴥ', 'ㄹ', 'ㅏ', 'ㄱ', 'ᴥ', 'ㅎ', 'ㅏ', 'ᴥ', 'ㄴ', 'ㅣ', 'ᴥ', ' ', 'ㅁ', 'ㅏ', 'ㄹ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㅅ', 'ㅜ', 'ᴥ', 'ㄹ', 'ㅏ', 'ᴥ', 'ㅅ', 'ㅣ', 'ᴥ', 'ㄱ', 'ㅏ', 'ᴥ', ' ', 'ㅈ', 'ㅓ', 'ㄱ', 'ᴥ', 'ㅍ', 'ㅡ', 'ㄹ', 'ᴥ', 'ㅎ', 'ㅏ', 'ᴥ', 'ㄱ', 'ㅗ', 'ᴥ', ' ', 'ㅎ', 'ㅏ', 'ㅇ', 'ᴥ', 'ㄱ', 'ㅗ', 'ㅇ', 'ᴥ', ' ', 'ㄱ', 'ㅣ', 'ᴥ', 'ㅊ', 'ㅣ', 'ᴥ', 'ㅎ', 'ㅏ', 'ᴥ', 'ㄹ', 'ㅣ', 'ᴥ', 'ㅇ', 'ㅛ', 'ㅂ', 'ᴥ', '.', ' ', 'ㅅ', 'ㅡ', 'ㅇ', 'ᴥ', 'ㅅ', 'ㅏ', 'ㅇ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㅇ', 'ㅛ', 'ㅇ', 'ᴥ', 'ㅅ', 'ㅏ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㅂ', 'ㅏ', 'ㄴ', 'ᴥ', 'ㅂ', 'ㅕ', 'ㅇ', 'ᴥ', 'ㅎ', 'ㅣ', 'ᴥ', ' ', 'ㄱ', 'ㅏ', 'ㅁ', 'ᴥ', 'ㄷ', 'ㅐ', 'ᴥ', 'ㅍ', 'ㅜ', 'ㄹ', 'ᴥ', 'ㅇ', 'ㅗ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅔ', 'ᴥ', ' ', 'ㅊ', 'ㅓ', 'ㅇ', 'ᴥ', 'ㅇ', 'ㅜ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ㅍ', 'ᴥ', 'ㄱ', 'ㅗ', 'ᴥ', ' ', 'ㄴ', 'ㅐ', 'ᴥ', 'ㅎ', 'ㅕ', 'ㄴ', 'ᴥ', ' ', 'ㅁ', 'ㅏ', 'ᴥ', 'ㄹ', 'ㅣ', 'ㅁ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㅁ', 'ᴥ', 'ㅎ', 'ㅏ', 'ᴥ', 'ㅁ', 'ㅕ', 'ᴥ', ' ', 'ㄱ', 'ㅏ', 'ᴥ', 'ㄹ', 'ㅏ', 'ᴥ', 'ㅎ', 'ㅏ', 'ㄴ', 'ᴥ', ' ', 'ㄷ', 'ㅓ', 'ㅁ', 'ᴥ', 'ㄴ', 'ㅣ', 'ᴥ', 'ㄹ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㄴ', 'ㅏ', 'ᴥ', 'ㄹ', 'ㅣ', 'ᴥ', 'ㄲ', 'ㅏ', 'ᴥ', 'ㄱ', 'ㅗ', 'ᴥ', ' ', 'ㅅ', 'ㅏ', 'ᴥ', 'ㅂ', 'ㅣ', 'ᴥ', 'ㅇ', 'ㅔ', 'ᴥ', ' ', 'ㅇ', 'ㅘ', 'ᴥ', 'ㅇ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅔ', 'ᴥ', ' ', 'ㄴ', 'ㅓ', 'ᴥ', 'ㄹ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', '\\n', 'ㄱ', 'ㅏ', 'ᴥ', 'ㄹ', 'ㅣ', 'ᴥ', 'ㄴ', 'ㅣ', 'ᴥ', 'ㄱ', 'ㅓ', 'ᴥ', 'ㄷ', 'ㅗ', 'ᴥ', ' ', 'ㅊ', 'ㅓ', 'ㅂ', 'ᴥ', 'ㄱ', 'ㅏ', 'ᴥ', ' ', 'ㅎ', 'ㅏ', 'ᴥ', 'ㄴ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㄱ', 'ㅓ', 'ㅅ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㅇ', 'ㅑ', 'ᴥ', '?', ' ', 'ㅅ', 'ㅔ', 'ᴥ', 'ㅁ', 'ㅜ', 'ᴥ', 'ㅇ', 'ㅢ', 'ᴥ', ' ', 'ㅈ', 'ㅜ', 'ㄹ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', '\\n', 'ㄱ', 'ㅓ', 'ㄴ', 'ᴥ', 'ㄱ', 'ㅣ', 'ᴥ', 'ㅈ', 'ㅏ', 'ᴥ', ' ', 'ㅇ', 'ㅘ', 'ㅇ', 'ᴥ', 'ㅅ', 'ㅏ', 'ㅇ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㅁ', 'ㅜ', 'ᴥ', 'ㄷ', 'ㅡ', 'ᴥ', 'ㄱ', 'ㅗ', 'ᴥ', ' ', 'ㅇ', 'ㅕ', 'ㅇ', 'ᴥ', 'ㅁ', 'ㅕ', 'ㅇ', 'ᴥ', 'ㅆ', 'ㅣ', 'ᴥ', ' ', 'ㅇ', 'ㅝ', 'ᴥ', 'ㅇ', 'ㅣ', 'ㄹ', 'ᴥ', ' ', 'ㄱ', 'ㅓ', 'ㅅ', 'ᴥ', 'ㄱ', 'ㅘ', 'ᴥ', ' ', 'ㄷ', 'ㅜ', 'ㄹ', 'ᴥ', 'ㅇ', 'ㅓ', 'ᴥ', 'ㄱ', 'ㅏ', 'ᴥ', ' ', 'ㅁ', 'ㅗ', 'ᴥ', 'ㅅ', 'ㅣ', 'ㅆ', 'ᴥ', 'ㄷ', 'ㅏ', 'ᴥ', 'ㅅ', 'ㅏ', 'ᴥ', ' ', 'ㄴ', 'ㅗ', 'ㄹ', 'ᴥ', 'ㄹ', 'ㅣ', 'ㅁ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㄴ', 'ㅐ', 'ᴥ', 'ㄱ', 'ㅓ', 'ㅁ', 'ᴥ', 'ㅎ', 'ㅣ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㅇ', 'ㅔ', 'ᴥ', ' ', 'ㅁ', 'ㅏ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㅁ', 'ᴥ', 'ㄹ', 'ㅏ', 'ㅇ', 'ᴥ', 'ㅇ', 'ㅡ', 'ᴥ', 'ㄹ', 'ㅗ', 'ᴥ', ' ', 'ㄷ', 'ㅏ', 'ㄹ', 'ᴥ', 'ㅇ', 'ㅏ', 'ᴥ', 'ㅇ', 'ㅕ', 'ㅆ', 'ᴥ', 'ㄷ', 'ㅐ', 'ᴥ', '?', ' ', '\\n', 'ㅊ', 'ㅓ', 'ㄴ', 'ᴥ', 'ㅅ', 'ㅗ', 'ᴥ', 'ㅎ', 'ㅏ', 'ᴥ', 'ㄱ', 'ㅗ', 'ᴥ', ' ', 'ㄱ', 'ㅡ', 'ᴥ', 'ㅁ', 'ㅜ', 'ᴥ', ' ', 'ㅌ', 'ㅐ', 'ᴥ', 'ㅈ', 'ㅏ', 'ᴥ', 'ㄷ', 'ㅗ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㅎ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㅅ', 'ㅡ', 'ㅂ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㅈ', 'ㅏ', 'ㅇ', 'ᴥ', 'ㄱ', 'ㅕ', 'ᴥ', ' ', 'ㄷ', 'ㅡ', 'ㄹ', 'ᴥ', 'ㅇ', 'ㅓ', 'ᴥ', 'ㅇ', 'ㅓ', 'ᴥ', 'ㄱ', 'ㅏ', 'ㅆ', 'ᴥ', 'ㄷ', 'ㅏ', 'ᴥ', '.', ' ', 'ㅅ', 'ㅗ', 'ᴥ', 'ㅊ', 'ㅓ', 'ㄱ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㅁ', 'ㅏ', 'ㅈ', 'ᴥ', 'ㅇ', 'ㅏ', 'ᴥ', ' ', 'ㅇ', 'ㅓ', 'ᴥ', 'ㄸ', 'ㅐ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㅊ', 'ㅓ', 'ㄴ', 'ᴥ', 'ㄴ', 'ㅏ', 'ㅢ', 'ᴥ', ' ', 'ㄱ', 'ㅜ', 'ㄱ', 'ᴥ', 'ㅅ', 'ㅗ', 'ᴥ', 'ㄹ', 'ㅏ', 'ᴥ', ' ', 'ㅈ', 'ㅓ', 'ㄴ', 'ᴥ', 'ㄱ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', '\\n', 'ㅎ', 'ㅏ', 'ᴥ', 'ㅁ', 'ㅕ', 'ㄴ', 'ᴥ', ' ', 'ㄱ', 'ㅡ', 'ᴥ', ' ', 'ㅇ', 'ㅓ', 'ᴥ', 'ㅉ', 'ㅣ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ㅆ', 'ᴥ', 'ㄱ', 'ㅛ', 'ㅆ', 'ᴥ', 'ㄷ', 'ㅡ', 'ᴥ', 'ᴥ', 'ㅇ', 'ㅕ', 'ㅄ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㅅ', 'ㅏ', 'ᴥ', 'ㄹ', 'ㅏ', 'ㅇ', 'ᴥ', 'ㅇ', 'ㅢ', 'ᴥ', ' ', 'ㅅ', 'ㅐ', 'ㅇ', 'ᴥ', 'ㅂ', 'ㅜ', 'ᴥ', 'ㄷ', 'ㅗ', 'ᴥ', 'ㄹ', 'ㅕ', 'ᴥ', ' ', 'ㅈ', 'ㅣ', 'ᴥ', 'ㄷ', 'ㅗ', 'ᴥ', 'ㄱ', 'ㅏ', 'ᴥ', ' ', 'ㅎ', 'ㅣ', 'ᴥ', 'ㅁ', 'ㅕ', 'ㄴ', 'ᴥ', ' ', 'ㅎ', 'ㅏ', 'ㄴ', 'ᴥ', ' ', 'ㅂ', 'ㅏ', 'ᴥ', 'ㄱ', 'ㅗ', 'ᴥ', ' ', 'ㅇ', 'ㅏ', 'ㅁ', 'ᴥ', 'ㅁ', 'ㅏ', 'ᴥ', 'ㄹ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', '\\n', 'ㅅ', 'ㅣ', 'ᴥ', 'ㄹ', 'ㅓ', 'ᴥ', 'ㄴ', 'ㅏ', 'ᴥ', ' ', 'ㄱ', 'ㅏ', 'ᴥ', 'ㅁ', 'ㅜ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㄴ', 'ㅏ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㄱ', 'ㅏ', 'ㄱ', 'ᴥ', 'ㄱ', 'ㅔ', 'ᴥ', ' ', 'ㅎ', 'ㅏ', 'ㅁ', 'ᴥ', 'ㅇ', 'ㅔ', 'ᴥ', ' ', 'ㅁ', 'ㅏ', 'ㄹ', 'ᴥ', 'ㅎ', 'ㅣ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ㅆ', 'ᴥ', 'ㄴ', 'ㅡ', 'ㄴ', 'ᴥ', 'ㅈ', 'ㅔ', 'ᴥ', ',', ' ', 'ㄱ', 'ㅏ', 'ㅌ', 'ᴥ', 'ㅇ', 'ㅡ', 'ᴥ', 'ㅁ', 'ㅕ', 'ㄴ', 'ᴥ', '\\n', 'ㅅ', 'ㅏ', 'ᴥ', 'ㅁ', 'ㅏ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㄷ', 'ㅗ', 'ㅇ', 'ᴥ', 'ㅅ', 'ㅏ', 'ᴥ', 'ㄴ', 'ㅢ', 'ᴥ', ' ', 'ㅅ', 'ㅓ', 'ㄴ', 'ᴥ', 'ㅅ', 'ㅠ', 'ᴥ', 'ㄴ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㅈ', 'ㅚ', 'ᴥ', 'ㄹ', 'ㅡ', 'ㅂ', 'ᴥ', 'ㄷ', 'ㅗ', 'ᴥ', ' ', 'ㅅ', 'ㅏ', 'ᴥ', 'ㅇ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㄱ', 'ㅘ', 'ᴥ', ' ', 'ㅁ', 'ㅏ', 'ㄹ', 'ᴥ', 'ㅂ', 'ㅣ', 'ᴥ', 'ㄹ', 'ㅜ', 'ㅅ', 'ᴥ', 'ㅎ', 'ㅕ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㄸ', 'ㅗ', 'ᴥ', 'ㄹ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', '\\n', 'ㄱ', 'ㅡ', 'ᴥ', 'ㄹ', 'ㅓ', 'ㅁ', 'ᴥ', 'ㅈ', 'ㅣ', 'ᴥ', 'ㄹ', 'ㅏ', 'ᴥ', ' ', 'ㅇ', 'ㅗ', 'ㅎ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㄱ', 'ㅜ', 'ㄱ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', 'ㅇ', 'ㅘ', 'ㅆ', 'ᴥ', 'ㄷ', 'ㅗ', 'ᴥ', 'ㄷ', 'ㅏ', 'ᴥ', '.', ' ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㄴ', 'ㅣ', 'ᴥ', ',', ' ', 'ㄴ', 'ㅐ', 'ᴥ', ' ', 'ㄸ', 'ㅗ', 'ᴥ', 'ㅎ', 'ㅏ', 'ㄴ', 'ᴥ', ' ', 'ㄱ', 'ㅏ', 'ᴥ', 'ㅈ', 'ㅣ', 'ᴥ', 'ㅎ', 'ㅏ', 'ᴥ', 'ㄷ', 'ㅚ', 'ᴥ', '\\n', ' ', ' ', '\"', 'ㅇ', 'ㅣ', 'ᴥ', 'ㄸ', 'ㅚ', 'ᴥ', 'ㄱ', 'ㅓ', 'ㄴ', 'ᴥ', ' ', 'ㅂ', 'ㅏ', 'ㅇ', 'ᴥ', 'ㅆ', 'ㅏ', 'ᴥ', 'ㅅ', 'ㅐ', 'ㅇ', 'ᴥ', 'ㅅ', 'ㅓ', 'ㅄ', 'ᴥ', 'ㅇ', 'ㅡ', 'ᴥ', 'ㄴ', 'ㅣ', 'ᴥ', ' ', 'ㅈ', 'ㅓ', 'ᴥ', 'ㅊ', 'ㅣ', 'ᴥ', 'ㄴ', 'ㅣ', 'ㄴ', 'ᴥ', ' ', 'ㅇ', 'ㅏ', 'ᴥ', 'ㅅ', 'ㅣ', 'ㅁ', 'ᴥ', 'ㅅ', 'ㅏ', 'ᴥ', 'ㄹ', 'ㅏ', 'ㅇ', 'ᴥ', 'ㅇ', 'ㅔ', 'ᴥ', ' ', 'ㄱ', 'ㅏ', 'ㅁ', 'ᴥ', 'ㅇ', 'ㅏ', 'ㄱ', 'ᴥ', 'ㅎ', 'ㅐ', 'ㅆ', 'ᴥ', 'ㄷ', 'ㅏ', 'ᴥ', '.', ' ', '\\n', ' ', ' ', '\"', 'ㄴ', 'ㅏ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅕ', 'ㅇ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㄷ', 'ㅏ', 'ᴥ', 'ㅅ', 'ㅣ', 'ᴥ', ' ', 'ㅇ', 'ㅏ', 'ᴥ', 'ㄴ', 'ㅣ', 'ᴥ', 'ㄹ', 'ㅏ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㅁ', 'ㅕ', 'ᴥ', ' ', 'ㅁ', 'ㅏ', 'ㄹ', 'ᴥ', 'ㅇ', 'ㅛ', 'ᴥ', 'ㄱ', 'ㅏ', 'ㄱ', 'ᴥ', 'ㅎ', 'ㅏ', 'ᴥ', 'ㄱ', 'ㅣ', 'ᴥ', 'ㄹ', 'ㅡ', 'ㄹ', 'ᴥ', ',', ' ', '\\n', ' ', ' ', '\"', 'ㅅ', 'ㅏ', 'ᴥ', 'ㄹ', 'ㅏ', 'ㅁ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㄷ', 'ㅏ', 'ᴥ', 'ㄱ', 'ㅟ', 'ᴥ', ' ', 'ㅂ', 'ㅏ', 'ㅁ', 'ᴥ', ' ', 'ㅈ', 'ㅏ', 'ㅅ', 'ᴥ', 'ㅇ', 'ㅔ', 'ᴥ', ' ', 'ㄱ', 'ㅡ', 'ᴥ', 'ㄹ', 'ㅗ', 'ᴥ', 'ㄹ', 'ㅜ', 'ᴥ', 'ㅂ', 'ㅗ', 'ᴥ', 'ㅁ', 'ㅕ', 'ㄴ', 'ᴥ', ' ', 'ㅎ', 'ㅏ', 'ᴥ', 'ㅅ', 'ㅣ', 'ᴥ', 'ㅁ', 'ㅕ', 'ㄴ', 'ᴥ', ' ', 'ㄷ', 'ㅗ', 'ㄹ', 'ᴥ', 'ㅇ', 'ㅏ', 'ᴥ', 'ㅇ', 'ㅘ', 'ㅆ', 'ᴥ', 'ㄴ', 'ㅏ', 'ᴥ', 'ㄷ', 'ㅏ', 'ᴥ', '.', ' ', 'ㄴ', 'ㅓ', 'ᴥ', 'ㅊ', 'ㅣ', 'ㄴ', 'ᴥ', ' ', 'ㅅ', 'ㅏ', 'ᴥ', 'ㄹ', 'ㅏ', 'ㅁ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㅎ', 'ㅏ', 'ᴥ', 'ㄴ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㄱ', 'ㅗ', 'ㅌ', 'ᴥ', 'ㅅ', 'ㅏ', 'ㄱ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㅇ', 'ㅓ', 'ㅄ', 'ᴥ', 'ㅇ', 'ㅓ', 'ㅆ', 'ᴥ', 'ㄷ', 'ㅏ', 'ᴥ', '.', ' ', '\\n', ' ', ' ', 'ㅇ', 'ㅠ', 'ᴥ', 'ㄹ', 'ㅜ', 'ᴥ', ' ', 'ㅅ', 'ㅏ', 'ㅇ', 'ᴥ', 'ㄱ', 'ㅑ', 'ㅇ', 'ᴥ', 'ㄲ', 'ㅔ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ㄶ', 'ᴥ', 'ㅇ', 'ㅏ', 'ᴥ', ' ', 'ㅅ', 'ㅣ', 'ㅁ', 'ᴥ', 'ㅈ', 'ㅣ', 'ᴥ', ' ', 'ㅎ', 'ㅏ', 'ㅇ', 'ᴥ', 'ㄹ', 'ㅏ', 'ㅇ', 'ᴥ', 'ㅇ', 'ㅢ', 'ᴥ', ' ', 'ㅂ', 'ㅏ', 'ㅂ', 'ᴥ', 'ㅎ', 'ㅢ', 'ᴥ', ' ', 'ㄷ', 'ㅡ', 'ㄹ', 'ᴥ', 'ㅇ', 'ㅣ', 'ㄱ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㅅ', 'ㅏ', 'ᴥ', 'ㄹ', 'ㅏ', 'ㅁ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㄷ', 'ㅏ', 'ᴥ', 'ㄹ', 'ㅏ', 'ᴥ', ' ', 'ㄴ', 'ㅗ', 'ᴥ', 'ㅂ', 'ㅐ', 'ㄱ', 'ᴥ', 'ㅎ', 'ㅏ', 'ᴥ', 'ㄷ', 'ㅏ', 'ᴥ', '\\n', '\\n', ' ', ' ', '\"', 'ㅅ', 'ㅏ', 'ㅇ', 'ᴥ', 'ㄹ', 'ㅐ', 'ᴥ', 'ㅇ', 'ㅢ', 'ᴥ', ' ', 'ㅁ', 'ㅗ', 'ᴥ', 'ㅂ', 'ㅕ', 'ㅇ', 'ᴥ', 'ㅇ', 'ㅢ', 'ᴥ', ' ', 'ㅂ', 'ㅗ', 'ㅁ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㅁ', 'ㅗ', 'ㄷ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', 'ㄹ', 'ㅕ', 'ㄱ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ㅂ', 'ᴥ', 'ㄱ', 'ㅗ', 'ㄱ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㅎ', 'ㅣ', 'ᴥ', 'ㅁ', 'ㅕ', 'ㄱ', 'ᴥ', 'ㅅ', 'ㅣ', 'ᴥ', 'ㄹ', 'ㅏ', 'ᴥ', ' ', 'ㅂ', 'ㅣ', 'ᴥ', 'ㅊ', 'ㅕ', 'ㄴ', 'ᴥ', ' ', 'ㅇ', 'ㅏ', 'ㅀ', 'ᴥ', 'ㅇ', 'ㅡ', 'ᴥ', 'ㅁ', 'ㅕ', 'ᴥ', ' ', 'ㅅ', 'ㅔ', 'ᴥ', 'ㅂ', 'ㅜ', 'ᴥ', 'ㅎ', 'ㅏ', 'ᴥ', 'ㅇ', 'ㅕ', 'ᴥ', ' ', 'ㅅ', 'ㅏ', 'ᴥ', 'ㄹ', 'ㅏ', 'ㅁ', 'ᴥ', 'ㅇ', 'ㅡ', 'ᴥ', 'ㄹ', 'ㅗ', 'ᴥ', ' ', 'ㄱ', 'ㅓ', 'ㅍ', 'ᴥ', 'ㄱ', 'ㅓ', 'ᴥ', 'ㄴ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㅅ', 'ㅏ', 'ᴥ', 'ㅅ', 'ㅣ', 'ㄹ', 'ᴥ', ' ', '\\n', 'ㅂ', 'ㅗ', 'ᴥ', 'ㅁ', 'ㅣ', 'ᴥ', ' ', 'ㅎ', 'ㅏ', 'ㅊ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㅇ', 'ㅓ', 'ᴥ', 'ㅉ', 'ㅜ', 'ᴥ', 'ㄷ', 'ㅏ', 'ᴥ', 'ㄱ', 'ㅏ', 'ᴥ', 'ㅅ', 'ㅓ', 'ᴥ', ' ', 'ㄴ', 'ㅏ', 'ㅇ', 'ᴥ', 'ㅈ', 'ㅏ', 'ᴥ', 'ㅎ', 'ㅏ', 'ㄴ', 'ᴥ', ' ', '\\n', 'ㄷ', 'ㅜ', 'ᴥ', ' ', 'ㅍ', 'ㅗ', 'ㅇ', 'ᴥ', 'ㅇ', 'ㅔ', 'ᴥ', ' ', 'ㅎ', 'ㅘ', 'ᴥ', 'ㅇ', 'ㅢ', 'ᴥ', ' ', 'ㄱ', 'ㅜ', 'ㅇ', 'ᴥ', 'ㅇ', 'ㅑ', 'ㅇ', 'ᴥ', 'ㅅ', 'ㅗ', 'ᴥ', 'ㄹ', 'ㅖ', 'ᴥ', ' ', 'ㅁ', 'ㅏ', 'ᴥ', 'ㄱ', 'ㅏ', 'ᴥ', 'ㅎ', 'ㅏ', 'ᴥ', 'ㄱ', 'ㅣ', 'ᴥ', 'ㄴ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㅅ', 'ㅗ', 'ㄱ', 'ᴥ', 'ㅇ', 'ㅑ', 'ㅇ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', 'ㅂ', 'ㅗ', 'ᴥ', 'ㅅ', 'ㅜ', 'ᴥ', ' ', 'ㅇ', 'ㅏ', 'ㄶ', 'ᴥ', 'ㄱ', 'ㅗ', 'ᴥ', ' ', 'ㅈ', 'ㅏ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㄱ', 'ㅏ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㅎ', 'ㅖ', 'ᴥ', ' ', 'ㄷ', 'ㅓ', 'ᴥ', 'ㄹ', 'ㅣ', 'ᴥ', 'ㅇ', 'ㅗ', 'ㅍ', 'ᴥ', 'ㄷ', 'ㅚ', 'ᴥ', 'ㅇ', 'ㅏ', 'ᴥ', ' ', 'ㅎ', 'ㅏ', 'ㄴ', 'ᴥ', ' ', 'ㅁ', 'ㅜ', 'ㄹ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', ' ', 'ㅂ', 'ㅜ', 'ᴥ', 'ㄷ', 'ㅐ', 'ㅂ', 'ᴥ', 'ㄷ', 'ㅏ', 'ㅁ', 'ᴥ', 'ㅇ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄹ', 'ᴥ', ' ', '\\n', 'ㅊ', 'ㅓ', 'ㅇ', 'ᴥ', 'ㄱ', 'ㅘ', 'ᴥ', ' ', 'ㄷ', 'ㅐ', 'ᴥ', 'ㅇ', 'ㅜ', 'ᴥ', 'ㅇ', 'ㅜ']\n",
      "\n",
      "-- 결과 --\n",
      "누구 인밖 이위에 다시 주몬 들온은 만이 친구함딘 마여 이어시기 같이 잎띠 \n",
      "같이 또한는 그 일으리를 뻔작감 귱경시려밥으로 버며 \n",
      "벼를 이름하여 적이 공재에 낸리라 할진다, 못으로 다더니와 조냥의리도 첨우로 부락하니 말을 수라시가 적플하고 항공 기치하리욥. 승상이 용산이 반병히 감대풀온에 청운을 잎고 내현 마림음하며 가라한 덤니를 나리까고 사비에 와인은에 너를 \n",
      "가리니거도 첩가 하는 것이야? 세무의 줄을 \n",
      "건기자 왕상을 이무드고 영명씨 워일 것과 둘어가 모싰다사 놀림이 내검히 이에 마음랑으로 달아였대? \n",
      "천소하고 그무 태자도 이흔 습을 장겨 들어어갔다. 소척이 맞아 어때을 천나ㅢ 국소라 전긴을 \n",
      "하면 그 어찌 있굤드엾을 사랑의 생부도려 지도가 히면 한 바고 암마를 \n",
      "시러나 가문이이나 인각게 함에 말히 있는제, 같으면\n",
      "사마이 동사늬 선슈는 죄릅도 사인과 말비룻혀 이 또를 \n",
      "그럼지라 옿은 국을왔도다. 이니, 내 또한 가지하되\n",
      "  \"이뙤건 방싸생섮으니 저치닌 아심사랑에 감악했다. \n",
      "  \"난영이 다시 아니라이며 말요각하기를, \n",
      "  \"사람은 다귀 밤 잣에 그로루보면 하시면 돌아왔나다. 너친 사람이 하늘 곹삭이 없었다. \n",
      "  유루 상걍께 읺아 심지 항랑의 밥희 들익을 사람이 다라 노백하다\n",
      "\n",
      "  \"상래의 모병의 봄을 몯을력을 입곡을 히멱시라 비쳔 앓으며 세부하여 사람으로 겊거늘 사실 \n",
      "보미 핯이 어쭈다가서 낭자한 \n",
      "두 퐁에 화의 궁양소례 마가하기는 속양을 보수 않고 자이가 이혜 더리옾되아 한 물이 부댑담인을 \n",
      "청과 대우\n"
     ]
    }
   ],
   "source": [
    "save_dir = 'data/nine_dreams'\n",
    "prime = decompose_text(\"누구 \")\n",
    "\n",
    "print (\"Prime Text : %s => %s\" % (automata(prime), \"\".join(prime)))\n",
    "n = 2000\n",
    "\n",
    "# 세션 설정\n",
    "session_conf = tf.ConfigProto()\n",
    "session_conf.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=session_conf)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "ckpt = tf.train.get_checkpoint_state(save_dir)\n",
    "\n",
    "# load_name = 'nine_dreams/model.ckpt-0'\n",
    "# load_name = 'nine_dreams/model.ckpt-99000'\n",
    "load_name = 'nine_dreams/model.ckpt-4000'\n",
    "\n",
    "print (load_name)\n",
    "\n",
    "saver.restore(sess, load_name)\n",
    "sampled_text = sample(sess, chars, vocab, probs, n, prime)\n",
    "#print (\"\")\n",
    "print (\"예시 문장 = %s\" % sampled_text)\n",
    "print (\"\")\n",
    "print (\"-- 결과 --\")\n",
    "print (automata(\"\".join(sampled_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
